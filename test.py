from __future__ import print_function
import argparse
import sys
import time
import torch
import torch.nn as nn
import torch.optim as optim
import torch.backends.cudnn as cudnn
from torch.autograd import Variable
import torch.utils.data as data
import torchvision
import torch.nn.functional as F
import torchvision.transforms as transforms
from data_loader import SYSUData, RegDBData, TestData, LLCMData
from data_manager import *
from eval_metrics import eval_sysu, eval_regdb, eval_llcm
from utils import *
from model import embed_net

import logging
import sys
import os

# from corruptions import corruption_transform


parser = argparse.ArgumentParser(description='PyTorch Cross-Modality Training')
# each changes
parser.add_argument('--noticed', default='VI-ReID-test', type=str)

parser.add_argument('--dataset', default='sysu', help='dataset name: regdb or sysu')
# 0.00068
parser.add_argument('--lr', default=0.2, type=float, help='learning rate, 0.00035 for adam, 0.0007for adamw')
parser.add_argument('--model_path', default='save_model/', type=str,
                    help='model save path')
parser.add_argument('--save_epoch', default=1000, type=int,
                    metavar='s', help='save model every 10 epochs')
parser.add_argument('--log_path', default='log/', type=str,
                    help='log save path')
parser.add_argument('--workers', default=0, type=int, metavar='N',
                    help='number of data loading workers (default: 4)')
parser.add_argument('--img_w', default=144, type=int,
                    metavar='imgw', help='img width')
parser.add_argument('--img_h', default=288, type=int,
                    metavar='imgh', help='img height')
parser.add_argument('--batch-size', default=6, type=int,
                    metavar='B', help='training batch size')
parser.add_argument('--num_pos', default=4, type=int,
                    help='num of pos per identity in each modality')
parser.add_argument('--test-batch', default=64, type=int,
                    metavar='tb', help='testing batch size')
parser.add_argument('--margin', default=0.5, type=float,
                    metavar='margin', help='triplet loss margin')
parser.add_argument('--resume', '-r', default='sysu_p6_n4_lr_0.2_seed_0_best.pth', type=str,
                    help='resume from checkpoint')

parser.add_argument('--trial', default=1, type=int,
                    metavar='t', help='trial (only for RegDB dataset)')

parser.add_argument('--seed', default=0, type=int,
                    metavar='t', help='random seed')
parser.add_argument('--mode', default='all', type=str, help='all or indoor')
parser.add_argument('--gpu', default='0,1,2,3', type=str,
                    help='gpu device ids for CUDA_VISIBLE_DEVICES')
parser.add_argument('--pool_dim', default=2048)
parser.add_argument('--decay_step', default=16)
parser.add_argument('--warm_up_epoch', default=8, type=int)
parser.add_argument('--max_epoch', default=100)
parser.add_argument('--rerank', default='no', type=str)
parser.add_argument('--dim', default=2048, type=int)
parser.add_argument('--tvsearch', default=0, type=int, help='1:visible to infrared, 0:infrared to visible')
parser.add_argument('--tta', default=True, type=bool)
args = parser.parse_args()
os.environ['CUDA_VISIBLE_DEVICES'] = args.gpu
set_seed(args.seed)
device = 'cuda' if torch.cuda.is_available() else 'cpu'


##############文件写入#######

# 创建日志目录（如果不存在）
os.makedirs(args.log_path, exist_ok=True)

# 生成带 mode 的日志文件名
log_filename = os.path.join(
    args.log_path,
    f'{args.dataset}_test_{args.mode}.txt'
)

# 设置 logging
logging.basicConfig(
    filename=log_filename,
    level=logging.INFO,
    format='%(asctime)s: %(message)s'
)

# 同时输出到终端
console = logging.StreamHandler(sys.stdout)
console.setLevel(logging.INFO)
formatter = logging.Formatter('%(asctime)s: %(message)s')
console.setFormatter(formatter)
logging.getLogger('').addHandler(console)

##############文件写入#######


def extract_gall_feat(gallery_loader):
    with torch.no_grad():
        model.eval()
        # print('Extracting gallery features...')
        start_time = time.time()
        ptr = 0
        gallery_feats = np.zeros((ngall, args.dim))
        gallery_global_feats = np.zeros((ngall, args.dim))
        with torch.no_grad():
            for idx, (img, _) in enumerate(gallery_loader):
                img = Variable(img.to(device))
                global_feat, feat = model(img, img, modal=test_mode[0])
                if args.tta:
                    global_feat_tta, feat_tta = model(torch.flip(img, dims=[3]), torch.flip(img, dims=[3]), modal=test_mode[0])
                    global_feat += global_feat_tta
                    feat += feat_tta
                batch_num = img.size(0)
                gallery_feats[ptr:ptr + batch_num, :] = feat.cpu().numpy()
                gallery_global_feats[ptr:ptr + batch_num, :] = global_feat.cpu().numpy()
                ptr = ptr + batch_num
        duration = time.time() - start_time
    # print('Extracting time: {}s'.format(int(round(duration))))
    return gallery_global_feats, gallery_feats


def extract_query_feat(query_loader):
    with torch.no_grad():
        model.eval()
        # print('Extracting query features...')
        start_time = time.time()
        ptr = 0
        query_feats = np.zeros((nquery, args.dim))
        query_global_feats = np.zeros((nquery, args.dim))
        with torch.no_grad():
            for idx, (img, _) in enumerate(query_loader):
                img = Variable(img.to(device))
                batch_num = img.size(0)
                global_feat, feat = model(img, img, modal=test_mode[1])
                if args.tta:
                    global_feat_tta, feat_tta = model(torch.flip(img, dims=[3]), torch.flip(img, dims=[3]), modal=test_mode[1])
                    global_feat += global_feat_tta
                    feat += feat_tta
                query_feats[ptr:ptr + batch_num, :] = feat.cpu().numpy()
                query_global_feats[ptr:ptr + batch_num, :] = global_feat.cpu().numpy()
                ptr = ptr + batch_num
        duration = time.time() - start_time
        # print('Extracting time: {}s'.format(int(round(duration))))
    return query_global_feats, query_feats


args, unparsed = parser.parse_known_args()
if args.dataset == 'sysu':
    data_path = 'datasets/SYSU-MM01/'
    num_classes = 395
    test_mode = [1, 2]
elif args.dataset == 'regdb':
    data_path = 'datasets/RegDB/'
    num_classes = 206
    test_mode = [1, 2]
elif args.dataset == 'llcm':
    data_path = 'datasets/LLCM/'
    num_classes = 713
    # T2V
    if args.tvsearch:
        test_mode = [2, 1]
        print('Visible to Infrared......')
    else:
        test_mode = [1, 2]
        print('Infrared to Visible......')
else:
    raise Exception('Invalid dataset name......')

cudnn.benchmark = True
# cudnn.deterministic = True

logging.info('==> Building model......')

model = embed_net(class_num=num_classes)
model.to(device)

logging.info('==> Testing......')
# define transforms
normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])

transform_test = transforms.Compose([
    transforms.ToPILImage(),
    transforms.Resize((args.img_h, args.img_w)),
    transforms.ToTensor(),
    normalize])

end = time.time()

if args.dataset == 'sysu':
    if len(args.resume) > 0:
        model_path = args.model_path + args.dataset + '/' + args.resume
        logging.info('==> Loading weights from checkpoint......')
        checkpoint = torch.load(model_path)
        logging.info(f'==> best epoch: {checkpoint["epoch"]}')
        #model.load_state_dict(checkpoint['net'])
        model.load_state_dict(checkpoint['net'], strict=False) #若仅仅改了模块名，可以用这个！！！
    else:
        logging.info('==> no checkpoint found at {}'.format(args.resume))
    query_img, query_label, query_cam = process_query_sysu(data_path, mode=args.mode)
    queryset = TestData(query_img, query_label, transform=transform_test, img_size=(args.img_w, args.img_h))
    query_loader = data.DataLoader(queryset, batch_size=args.test_batch, shuffle=False, num_workers=args.workers)
    nquery = len(query_label)
    query_feat, query_feat_att = extract_query_feat(query_loader)

    for trial in range(10):
        gall_img, gall_label, gall_cam = process_gallery_sysu(data_path, mode=args.mode, trial=trial)
        gallset = TestData(gall_img, gall_label, transform=transform_test, img_size=(args.img_w, args.img_h))
        gall_loader = data.DataLoader(gallset, batch_size=args.test_batch, shuffle=False, num_workers=args.workers)
        ngall = len(gall_label)
        gall_feat, gall_feat_att = extract_gall_feat(gall_loader)

        distmat = -np.matmul(query_feat, np.transpose(gall_feat))
        distmat_att = -np.matmul(query_feat_att, np.transpose(gall_feat_att))

        cmc, mAP, mINP = eval_sysu(distmat, query_label, gall_label, query_cam, gall_cam)
        cmc_att, mAP_att, mINP_att = eval_sysu(distmat_att, query_label, gall_label, query_cam, gall_cam)

        if trial == 0:

            all_cmc = cmc
            all_mAP = mAP
            all_mINP = mINP
            all_cmc_att = cmc_att
            all_mAP_att = mAP_att
            all_mINP_att = mINP_att

        else:

            all_cmc += cmc
            all_mAP += mAP
            all_mINP += mINP
            all_cmc_att += cmc_att
            all_mAP_att += mAP_att
            all_mINP_att += mINP_att

        logging.info('Test Trial: {}'.format(trial))
        logging.info(
            'original feature:   Rank-1: {:.2%} | Rank-5: {:.2%} | Rank-10: {:.2%}| Rank-20: {:.2%}| mAP: {:.2%}| mINP: {:.2%}'.format(
                cmc[0], cmc[4], cmc[9], cmc[19], mAP, mINP))
        logging.info(
            'feature after BN:   Rank-1: {:.2%} | Rank-5: {:.2%} | Rank-10: {:.2%}| Rank-20: {:.2%}| mAP: {:.2%}| mINP: {:.2%}'.format(
                cmc_att[0], cmc_att[4], cmc_att[9], cmc_att[19], mAP_att, mINP_att))





elif args.dataset == 'llcm':
    if len(args.resume) > 0:
        model_path = args.model_path + args.dataset + '/' + args.resume
        logging.info('==> Loading weights from checkpoint......')
        checkpoint = torch.load(model_path)
        logging.info('==> best epoch', checkpoint['epoch'])
        # model.load_state_dict(checkpoint['net'])
        model.load_state_dict(checkpoint['net'], strict=False)  # 若仅仅改了模块名，可以用这个！！！
    else:
        logging.info('==> no checkpoint found at {}'.format(args.resume))

    query_img, query_label, query_cam = process_query_llcm(data_path, mode=test_mode[1])
    queryset = TestData(query_img, query_label, transform=transform_test, img_size=(args.img_w, args.img_h))
    query_loader = data.DataLoader(queryset, batch_size=args.test_batch, shuffle=False, num_workers=args.workers)
    nquery = len(query_label)
    query_feat, query_feat_att = extract_query_feat(query_loader)

    for trial in range(10):
        gall_img, gall_label, gall_cam = process_gallery_llcm(data_path, mode=test_mode[0], trial=trial)
        gallset = TestData(gall_img, gall_label, transform=transform_test, img_size=(args.img_w, args.img_h))
        # gallset = TestData(gall_img, gall_label, transform=corruption_transform_test, img_size=(args.img_w, args.img_h))
        gall_loader = data.DataLoader(gallset, batch_size=args.test_batch, shuffle=False, num_workers=args.workers)
        ngall = len(gall_label)
        gall_feat, gall_feat_att = extract_gall_feat(gall_loader)

        distmat = -np.matmul(query_feat, np.transpose(gall_feat))
        distmat_att = -np.matmul(query_feat_att, np.transpose(gall_feat_att))

        cmc, mAP, mINP = eval_llcm(distmat, query_label, gall_label, query_cam, gall_cam)
        cmc_att, mAP_att, mINP_att = eval_llcm(distmat_att, query_label, gall_label, query_cam, gall_cam)

        if trial == 0:

            all_cmc = cmc
            all_mAP = mAP
            all_mINP = mINP
            all_cmc_att = cmc_att
            all_mAP_att = mAP_att
            all_mINP_att = mINP_att

        else:

            all_cmc += cmc
            all_mAP += mAP
            all_mINP += mINP
            all_cmc_att += cmc_att
            all_mAP_att += mAP_att
            all_mINP_att += mINP_att

        logging.info('Test Trial: {}'.format(trial))
        logging.info(
            'original feature:   Rank-1: {:.2%} | Rank-5: {:.2%} | Rank-10: {:.2%}| Rank-20: {:.2%}| mAP: {:.2%}| mINP: {:.2%}'.format(
                cmc[0], cmc[4], cmc[9], cmc[19], mAP, mINP))
        logging.info(
            'feature after BN:   Rank-1: {:.2%} | Rank-5: {:.2%} | Rank-10: {:.2%}| Rank-20: {:.2%}| mAP: {:.2%}| mINP: {:.2%}'.format(
                cmc_att[0], cmc_att[4], cmc_att[9], cmc_att[19], mAP_att, mINP_att))


elif args.dataset == 'regdb':
    for trial in range(10):
        test_trial = trial + 1
        model_path = args.model_path + args.dataset + '/' + 'regdb_p6_n4_lr_0.1_seed_0_trial_{}_best.pth'.format(
            test_trial)
        checkpoint = torch.load(model_path)
        logging.info('==> best epoch', checkpoint['epoch'])
        # model.load_state_dict(checkpoint['net'])
        model.load_state_dict(checkpoint['net'], strict=False)  # 若仅仅改了模块名，可以用这个！！！
        query_img, query_label = process_test_regdb(data_path, trial=test_trial, modal='thermal')
        gall_img, gall_label = process_test_regdb(data_path, trial=test_trial, modal='visible')

        gallset = TestData(gall_img, gall_label, transform=transform_test, img_size=(args.img_w, args.img_h))
        queryset = TestData(query_img, query_label, transform=transform_test, img_size=(args.img_w, args.img_h))

        gall_loader = data.DataLoader(gallset, batch_size=args.test_batch, shuffle=False, num_workers=args.workers)
        query_loader = data.DataLoader(queryset, batch_size=args.test_batch, shuffle=False, num_workers=args.workers)

        nquery = len(query_label)
        ngall = len(gall_label)

        query_feat, query_feat_att = extract_query_feat(query_loader)
        gall_feat, gall_feat_att = extract_gall_feat(gall_loader)

        if args.tvsearch:
            # compute the similarity
            distmat = -np.matmul(gall_feat, np.transpose(query_feat))
            distmat_att = -np.matmul(gall_feat_att, np.transpose(query_feat_att))
            # evaluation
            cmc, mAP, mINP = eval_regdb(distmat, gall_label, query_label)
            cmc_att, mAP_att, mINP_att = eval_regdb(distmat_att, gall_label, query_label)

        else:
            distmat = -np.matmul(query_feat, np.transpose(gall_feat))
            distmat_att = -np.matmul(query_feat_att, np.transpose(gall_feat_att))

            cmc, mAP, mINP = eval_regdb(distmat, query_label, gall_label)
            cmc_att, mAP_att, mINP_att = eval_regdb(distmat_att, query_label, gall_label)

        if trial == 0:
            all_cmc = cmc
            all_mAP = mAP
            all_mINP = mINP
            all_cmc_att = cmc_att
            all_mAP_att = mAP_att
            all_mINP_att = mINP_att

        else:
            all_cmc += cmc
            all_mAP += mAP
            all_mINP += mINP
            all_cmc_att += cmc_att
            all_mAP_att += mAP_att
            all_mINP_att += mINP_att

        if args.tvsearch:
            logging.info('Test Trial: {}, Visible to Thermal'.format(test_trial))
        else:
            logging.info('Test Trial: {}, Thermal to Visible'.format(test_trial))

        logging.info(
            'original feature:   Rank-1: {:.2%} | Rank-5: {:.2%} | Rank-10: {:.2%}| Rank-20: {:.2%}| mAP: {:.2%}| mINP: {:.2%}'.format(
                cmc[0], cmc[4], cmc[9], cmc[19], mAP, mINP))
        logging.info(
            'feature after BN:   Rank-1: {:.2%} | Rank-5: {:.2%} | Rank-10: {:.2%}| Rank-20: {:.2%}| mAP: {:.2%}| mINP: {:.2%}'.format(
                cmc_att[0], cmc_att[4], cmc_att[9], cmc_att[19], mAP_att, mINP_att))

all_cmc = all_cmc / 10
all_mAP = all_mAP / 10
all_mINP = all_mINP / 10
all_cmc_att = all_cmc_att / 10
all_mAP_att = all_mAP_att / 10
all_mINP_att = all_mINP_att / 10
logging.info('All Average:')
logging.info(
    'original feature:   Rank-1: {:.2%} | Rank-5: {:.2%} | Rank-10: {:.2%}| Rank-20: {:.2%}| mAP: {:.2%}| mINP: {:.2%}'.format(
        all_cmc[0], all_cmc[4], all_cmc[9], all_cmc[19], all_mAP, all_mINP))
logging.info(
    'feature after BN:   Rank-1: {:.2%} | Rank-5: {:.2%} | Rank-10: {:.2%}| Rank-20: {:.2%}| mAP: {:.2%}| mINP: {:.2%}'.format(
        all_cmc_att[0], all_cmc_att[4], all_cmc_att[9], all_cmc_att[19], all_mAP_att, all_mINP_att))

